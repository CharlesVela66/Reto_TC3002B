{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from pygments.lexers import JavaLexer\n",
    "from pygments import lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tokens(code):\n",
    "    \"\"\"\n",
    "    Extracts all tokens from the given Java code using Pygments.\n",
    "    \n",
    "    Args:\n",
    "        code (str): Java code as a string.\n",
    "        \n",
    "    Returns:\n",
    "        str: All tokens extracted from the code, joined by spaces.\n",
    "    \"\"\"\n",
    "    lexer = JavaLexer()\n",
    "    tokens = []\n",
    "    for ttype, value in lex(code, lexer):\n",
    "        if not str(ttype).startswith('Token.Text.Whitespace'):\n",
    "            val = value.strip()\n",
    "            if val:\n",
    "                tokens.append(f\"{ttype}:{val}\")\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_similarity(file1, file2, model_path, vectorizer_path, threshold = 0.50):\n",
    "    \"\"\"\n",
    "    Predicts the similarity between two Java code files using a pre-trained model.\n",
    "    \n",
    "    Args:\n",
    "        file1 (str): Path to the first Java code file.\n",
    "        file2 (str): Path to the second Java code file.\n",
    "        model_path (str): Path to the pre-trained model.\n",
    "        vectorizer_path (str): Path to the vectorizer used for feature extraction.\n",
    "        threshold (float): Similarity threshold for classification.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing the similarity score and a boolean indicating if the files are similar.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = joblib.load(model_path)\n",
    "    vectorizer = joblib.load(vectorizer_path)\n",
    "    \n",
    "    with open(file1, 'r', encoding='utf-8') as f:\n",
    "        code1 = f.read()\n",
    "    \n",
    "    with open(file2, 'r', encoding='utf-8') as f:\n",
    "        code2 = f.read()\n",
    "    \n",
    "    if len(code1.strip()) < 10 or len(code2.strip()) < 10:\n",
    "        return 0.0, False\n",
    "    \n",
    "    t1 = extract_tokens(code1)\n",
    "    t2 = extract_tokens(code2)\n",
    "    token_pair = f\"{t1} {t2}\"\n",
    "    \n",
    "    X = vectorizer.transform([token_pair])\n",
    "    \n",
    "    X_features = X.toarray()\n",
    "    \n",
    "    proba = model.predict_proba(X_features)[0]\n",
    "    similarity_score = proba[1] if len(proba) > 1 else proba[0]\n",
    "\n",
    "    is_similar = similarity_score >= threshold\n",
    "    \n",
    "    return similarity_score, is_similar\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTS\n",
      "SIMILARITY: 0.5087\n",
      "PLAGIARISM DETECTED: YES\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "file1 = \"original.java\"\n",
    "file2 = \"plagiarized.java\"\n",
    "    \n",
    "model_path = \"rf_model.pkl\"\n",
    "vectorizer_path = \"vectorizer.pkl\"\n",
    "    \n",
    "score, is_similar = predict_similarity(file1, file2, model_path, vectorizer_path)\n",
    "    \n",
    "print(\"\\nRESULTS\")\n",
    "print(f\"SIMILARITY: {score:.4f}\")\n",
    "print(f\"PLAGIARISM DETECTED: {'YES' if is_similar else 'NO'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
