{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b95bc34f",
      "metadata": {},
      "source": [
        "# Detector de plagio en código fuente (archivos .java)\n",
        "Este notebook presenta el desarrollo de un modelo para detectar plagio en archivos de código fuente escritos en Java. Se utiliza el dataset \"conplag\", ubicado en   `dataset/versions/b_plag_version_2`, el cual contiene carpetas con archivos originales y versiones plagiadas.\n",
        "\n",
        "## Objetivo\n",
        "Desarrollar una herramienta híbrida automatizada que detecte plagio en código fuente, combinando análisis léxico (tokenización) y técnicas de aprendizaje automático. El objetivo es alcanzar una precisión superior al 80% en la clasificación de código como plagiado o no plagiado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1ee15c5",
      "metadata": {},
      "source": [
        "## Importación de librerías\n",
        "Se importan las librerías necesarias para el procesamiento de archivos, tokenización de código Java, manipulación de datos y desarrollo del modelo de machine learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9eb6c7c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from pygments import lex\n",
        "from pygments.lexers import JavaLexer\n",
        "from pygments.token import Token\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00fd81c2",
      "metadata": {},
      "source": [
        "## Definición de rutas\n",
        "Se definen las rutas base para acceder al dataset y a los archivos de etiquetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "20022a95",
      "metadata": {},
      "outputs": [],
      "source": [
        "ROOT = Path().cwd().parent\n",
        "BASE_PATH = ROOT / \"dataset\" / \"versions\" / \"bplag_version_2\"\n",
        "LABELS_PATH = ROOT / \"dataset\" / \"versions\" / \"labels.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec18c12",
      "metadata": {},
      "source": [
        "## Lectura de archivos .java\n",
        "La función read_java_files() se encarga de recorrer recursivamente la estructura del dataset y leer el contenido de todos los archivos .java. Devuelve una lista con los identificadores de cada entrega y su respectivo código fuente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ed95e47a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_java_files(base_path):\n",
        "    \"\"\"\n",
        "    Recursively reads all .java files from the given base path.\n",
        "    \n",
        "    Args:\n",
        "        base_path (str): Path to the base directory containing submission pairs.\n",
        "    \n",
        "    Returns:\n",
        "        data (list): List of tuples (submission_id, code_content).\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    \n",
        "    for submission_pair in os.listdir(base_path):\n",
        "        pair_path = os.path.join(base_path, submission_pair)\n",
        "        \n",
        "        if os.path.isdir(pair_path):\n",
        "            for submission_id in os.listdir(pair_path):\n",
        "                submission_path = os.path.join(pair_path, submission_id)\n",
        "                \n",
        "                if os.path.isdir(submission_path):\n",
        "                    for file in os.listdir(submission_path):\n",
        "                        if file.endswith('.java'):\n",
        "                            file_path = os.path.join(submission_path, file)\n",
        "                            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                                code = f.read()\n",
        "                                data.append((submission_id, code))\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bbcf8253",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total submissions loaded: 1822\n",
            "\n",
            "First 2 submissions loaded:\n",
            "Submission ID: 5756162d\n",
            "Code snippet:\n",
            "import java.util.*;\n",
            "import java.io.*;\n",
            "public class EdD {\n",
            "\tpublic static void main(String[] args) throws Exception{\n",
            "\t\tint num = 998244353;\n",
            "\n",
            "\t\t// TODO Auto-generated method stub\n",
            " \t\tBufferedReader bf = new BufferedReader(new InputStreamReader(System.in));\n",
            " \t\tPrintWriter out = new PrintWriter(System.out...\n",
            "\n",
            "Submission ID: 808f7516\n",
            "Code snippet:\n",
            "import java.io.*;\n",
            "import java.math.BigInteger;\n",
            "import java.util.*;\n",
            "\n",
            "public class Main {\n",
            "    static int MOD = 1000000007;\n",
            "\n",
            "    // After writing solution, quick scan for:\n",
            "    //   array out of bounds\n",
            "    //   special cases e.g. n=1?\n",
            "    //\n",
            "    // Big numbers arithmetic bugs:\n",
            "    //   int overflow\n",
            "    ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "java_files_data = read_java_files(BASE_PATH)\n",
        "\n",
        "print(f\"Total submissions loaded: {len(java_files_data)}\")\n",
        "print(\"\\nFirst 2 submissions loaded:\")\n",
        "for submission_id, code in java_files_data[:2]:\n",
        "    print(f\"Submission ID: {submission_id}\\nCode snippet:\\n{code[:300]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26774854",
      "metadata": {},
      "source": [
        "## Extracción de tokens\n",
        "\n",
        "Para esta sección se utiliza la librería Pygments como analizador léxico. Esta librería permite extraer los tokens de un código fuente y clasificarlos en diferentes categorías. En este caso, se utilizará para extraer los tokens de código fuente en Java."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b981f462",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_tokens(code):\n",
        "    \"\"\"\n",
        "    Extracts tokens from the given Java code using Pygments.\n",
        "    \n",
        "    Args:\n",
        "        code (str): Java code as a string.\n",
        "        \n",
        "    Returns:\n",
        "        tokens (list): List of tokens extracted from the code.\n",
        "    \"\"\"\n",
        "    lexer = JavaLexer()\n",
        "    tokens = []\n",
        "    for ttype, value in lex(code, lexer):\n",
        "        if ttype in Token.Name or ttype in Token.Keyword or ttype in Token.Operator:\n",
        "            val = value.strip()\n",
        "            if val:\n",
        "                tokens.append(f\"{ttype.__class__.__name__}:{val}\")\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d12ecfda",
      "metadata": {},
      "source": [
        "## Preparación de los datos y etiquetas\n",
        "Se cargan las etiquetas desde el archivo labels.csv y se construye un diccionario para acceder fácilmente al veredicto (si un archivo es plagio o no) entre pares de entregas.\n",
        "\n",
        "Luego, se recorren los datos de código Java en pares, extrayendo los tokens de cada archivo y concatenándolos como una sola representación textual del par. \n",
        "\n",
        "Paralelamente, se asigna la etiqueta correspondiente (plagiado o no) a cada par utilizando el diccionario previamente generado.\n",
        "\n",
        "Este proceso genera dos listas:\n",
        "\n",
        "- token_pairs: Representación textual de los pares de código.\n",
        "\n",
        "- labels: Etiquetas binarias que indican si el par es plagiado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "58bd1fbe",
      "metadata": {},
      "outputs": [],
      "source": [
        "labels_df = pd.read_csv(LABELS_PATH)\n",
        "\n",
        "labels_dict = {}\n",
        "for _, row in labels_df.iterrows():\n",
        "    key = (row['sub1'], row['sub2'])\n",
        "    labels_dict[key] = row['verdict']\n",
        "\n",
        "token_pairs = []\n",
        "labels = []\n",
        "\n",
        "for i in range(0, len(java_files_data), 2):\n",
        "    try:\n",
        "        id1, code1 = java_files_data[i]\n",
        "        id2, code2 = java_files_data[i+1]\n",
        "    except IndexError:\n",
        "        break\n",
        "        \n",
        "    t1 = extract_tokens(code1)\n",
        "    t2 = extract_tokens(code2)\n",
        "    token_pairs.append(f\"{t1} {t2}\")\n",
        "    \n",
        "    if (id1, id2) in labels_dict:\n",
        "        labels.append(labels_dict[(id1, id2)])\n",
        "    elif (id2, id1) in labels_dict:\n",
        "        labels.append(labels_dict[(id2, id1)])\n",
        "    else:\n",
        "        print(f\"Warning: No label found for pair ({id1}, {id2})\")\n",
        "        labels.append(0) \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39a738c2",
      "metadata": {},
      "source": [
        "## Data Augmnentation\n",
        "Debido a que nuestro dataset original contenía menos de 1000 pares de código, el modelo tenía una exposición limitada a ejemplos variados, lo que afectaba negativamente su capacidad de generalización y su rendimiento predictivo. Para mitigar este problema, implementamos una estrategia de aumento de datos que multiplicó el tamaño del conjunto original por 3 veces.\n",
        "\n",
        "La función augment_token_sequence() permite generar nuevas versiones sintéticas de los pares de tokens aplicando pequeñas modificaciones controladas, lo que introduce variabilidad sin alterar significativamente la lógica del código original. Estas son las técnicas utilizadas:\n",
        "\n",
        "- Shuffle: Mezcla aleatoriamente grupos de tokens dentro de una ventana, simulando cambios menores en el orden del código que pueden aparecer en plagios.\n",
        "\n",
        "- Drop: Elimina tokens no críticos de forma aleatoria, simulando la omisión intencional de fragmentos para disimular el plagio.\n",
        "\n",
        "- Duplicate: Duplica tokens aleatoriamente para emular redundancias introducidas deliberadamente por quien plagia.\n",
        "\n",
        "- Synonym: Sustituye variables por sinónimos simulados (e.g., i por index), representando un cambio común en plagios superficiales.\n",
        "\n",
        "Estas transformaciones ayudan a enriquecer el entrenamiento del modelo, exponiéndolo a variaciones más realistas en los datos y mejorando su capacidad para identificar plagio con mayor precisión.\n",
        "\n",
        "La función generate_augmented_pairs() une los nuevos pares de tokens generados por la aumentación y les asigna las etiquetas correspondientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "037f4ca4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def augment_token_sequence(tokens, augmentation_method='shuffle', ratio=0.1):\n",
        "    \"\"\"\n",
        "    Augments a token sequence using various methods.\n",
        "    \n",
        "    Args:\n",
        "        tokens (str): The token sequence string to be augmented.\n",
        "        augmentation_method (str): The method to use for augmentation.\n",
        "            'shuffle': Randomly shuffles some tokens within a window.\n",
        "            'drop': Randomly drops some tokens.\n",
        "            'duplicate': Duplicates some tokens.\n",
        "            'synonym': Replaces some tokens with synonyms (simulated).\n",
        "        ratio (float): The percentage of tokens to modify (0.0 to 1.0).\n",
        "    \n",
        "    Returns:\n",
        "        str: The augmented token sequence as a string.\n",
        "    \"\"\"\n",
        "    token_list = tokens.split()\n",
        "    total_tokens = len(token_list)\n",
        "    num_to_modify = max(1, int(total_tokens * ratio))\n",
        "    \n",
        "    augmented_tokens = token_list.copy()\n",
        "    \n",
        "    if augmentation_method == 'shuffle':\n",
        "        for _ in range(num_to_modify // 2): \n",
        "            window_size = random.randint(2, 4) \n",
        "            if total_tokens <= window_size:\n",
        "                continue\n",
        "                \n",
        "            start_idx = random.randint(0, total_tokens - window_size)\n",
        "            window = augmented_tokens[start_idx:start_idx + window_size]\n",
        "            random.shuffle(window)\n",
        "            augmented_tokens[start_idx:start_idx + window_size] = window\n",
        "    \n",
        "    elif augmentation_method == 'drop':\n",
        "        critical_tokens = ['_TokenType:public', '_TokenType:class', '_TokenType:import', '_TokenType:static', '_TokenType:void', '_TokenType:main']\n",
        "        indices_to_drop = []\n",
        "        \n",
        "        for _ in range(num_to_modify):\n",
        "            valid_indices = [i for i, token in enumerate(augmented_tokens) \n",
        "                            if token not in critical_tokens and i not in indices_to_drop]\n",
        "            if not valid_indices:\n",
        "                break\n",
        "            idx = random.choice(valid_indices)\n",
        "            indices_to_drop.append(idx)\n",
        "        \n",
        "        augmented_tokens = [token for i, token in enumerate(augmented_tokens) if i not in indices_to_drop]\n",
        "    \n",
        "    elif augmentation_method == 'duplicate':\n",
        "        for _ in range(num_to_modify):\n",
        "            if not augmented_tokens:\n",
        "                break\n",
        "            idx = random.randint(0, len(augmented_tokens) - 1)\n",
        "            augmented_tokens.insert(idx, augmented_tokens[idx])\n",
        "    \n",
        "    elif augmentation_method == 'synonym':\n",
        "        variable_prefixes = ['_TokenType:i', '_TokenType:j', '_TokenType:k', '_TokenType:n', '_TokenType:m', '_TokenType:x', '_TokenType:y']\n",
        "        synonym_mapping = {\n",
        "            '_TokenType:i': ['_TokenType:idx', '_TokenType:index', '_TokenType:i'],\n",
        "            '_TokenType:j': ['_TokenType:jdx', '_TokenType:j'],\n",
        "            '_TokenType:k': ['_TokenType:kdx', '_TokenType:key', '_TokenType:k'],\n",
        "            '_TokenType:n': ['_TokenType:num', '_TokenType:size', '_TokenType:n'],\n",
        "            '_TokenType:m': ['_TokenType:max', '_TokenType:m'],\n",
        "            '_TokenType:x': ['_TokenType:xVal', '_TokenType:x'],\n",
        "            '_TokenType:y': ['_TokenType:yVal', '_TokenType:y']\n",
        "        }\n",
        "        \n",
        "        for _ in range(num_to_modify):\n",
        "            variable_indices = [i for i, token in enumerate(augmented_tokens) \n",
        "                               if any(token.startswith(prefix) for prefix in variable_prefixes)]\n",
        "            if not variable_indices:\n",
        "                break\n",
        "                \n",
        "            idx = random.choice(variable_indices)\n",
        "            token = augmented_tokens[idx]\n",
        "            \n",
        "            matching_prefix = next((prefix for prefix in variable_prefixes if token.startswith(prefix)), None)\n",
        "            if matching_prefix and matching_prefix in synonym_mapping:\n",
        "                augmented_tokens[idx] = random.choice(synonym_mapping[matching_prefix])\n",
        "    \n",
        "    return ' '.join(augmented_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "94c18ae1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_augmented_pairs(token_pairs, labels, augmentation_factor=2):\n",
        "    \"\"\"\n",
        "    Generates augmented token pairs and corresponding labels.\n",
        "    \n",
        "    Args:\n",
        "        token_pairs (list): Original token pairs.\n",
        "        labels (list): Original labels.\n",
        "        augmentation_factor (int): Number of augmentations per original sample.\n",
        "        \n",
        "    Returns:\n",
        "        tuple: (augmented_pairs, augmented_labels)\n",
        "    \"\"\"\n",
        "    augmentation_methods = ['shuffle', 'drop', 'duplicate', 'synonym']\n",
        "    augmented_pairs = []\n",
        "    augmented_labels = []\n",
        "    \n",
        "    for pair, label in zip(token_pairs, labels):\n",
        "        augmented_pairs.append(pair)\n",
        "        augmented_labels.append(label)\n",
        "        \n",
        "        parts = pair.split(' ', 1)\n",
        "        if len(parts) < 2:\n",
        "            continue  \n",
        "        \n",
        "        token_seq1, token_seq2 = parts\n",
        "        \n",
        "        for _ in range(augmentation_factor):\n",
        "            method1 = random.choice(augmentation_methods)\n",
        "            method2 = random.choice(augmentation_methods)\n",
        "            \n",
        "            aug_seq1 = augment_token_sequence(token_seq1, method1, ratio=0.1)\n",
        "            aug_seq2 = augment_token_sequence(token_seq2, method2, ratio=0.1)\n",
        "            \n",
        "            augmented_pair = f\"{aug_seq1} {aug_seq2}\"\n",
        "            \n",
        "            augmented_pairs.append(augmented_pair)\n",
        "            augmented_labels.append(label)\n",
        "    \n",
        "    return augmented_pairs, augmented_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66fc83ec",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original dataset size: 911\n",
            "Augmented dataset size: 2733\n",
            "\n",
            "Original class distribution:\n",
            "Label 0: 660 samples (72.45%)\n",
            "Label 1: 251 samples (27.55%)\n",
            "\n",
            "Augmented class distribution:\n",
            "Label 0: 1980 samples (72.45%)\n",
            "Label 1: 753 samples (27.55%)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Original dataset size: {len(token_pairs)}\")\n",
        "augmented_token_pairs, augmented_labels = generate_augmented_pairs(token_pairs, labels, augmentation_factor=2)\n",
        "print(f\"Augmented dataset size: {len(augmented_token_pairs)}\")\n",
        "\n",
        "original_unique, original_counts = np.unique(labels, return_counts=True)\n",
        "augmented_unique, augmented_counts = np.unique(augmented_labels, return_counts=True)\n",
        "\n",
        "print(f\"\\nOriginal class distribution:\")\n",
        "for label, count in zip(original_unique, original_counts):\n",
        "    print(f\"Label {label}: {count} samples ({count/len(labels)*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\nAugmented class distribution:\")\n",
        "for label, count in zip(augmented_unique, augmented_counts):\n",
        "    print(f\"Label {label}: {count} samples ({count/len(augmented_labels)*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5f33bd6",
      "metadata": {},
      "source": [
        "## Vectorización de Datos\n",
        "Una vez generadas las secuencias de tokens (originales y aumentadas), el siguiente paso es transformar estos textos en representaciones numéricas que puedan ser utilizadas por algoritmos de aprendizaje automático. Para ello, empleamos la técnica TF-IDF (Term Frequency–Inverse Document Frequency), que asigna pesos a cada token en función de su frecuencia en un documento.\n",
        "\n",
        "La función vectorize() se encarga de convertir los pares de tokens en una matriz dispersa, donde cada fila representa una instancia y cada columna una característica (token). Esta representación es fundamental para que el modelo pueda aprender patrones a partir del contenido del código fuente.\n",
        "\n",
        "En esta etapa se utilizó el conjunto de datos aumentado para asegurar una mejor cobertura léxica durante el proceso de vectorización."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e75ae232",
      "metadata": {},
      "outputs": [],
      "source": [
        "def vectorize(token_pairs):\n",
        "    \"\"\"\n",
        "    Vectorizes the given token pairs using TF-IDF.\n",
        "    \n",
        "    Args:\n",
        "        token_pairs (list): List of tokens to be vectorized.\n",
        "    \n",
        "    Returns:\n",
        "        vectorizer (TfidfVectorizer): Fitted TF-IDF vectorizer.\n",
        "        X (sparse matrix): TF-IDF matrix of the token pairs.\n",
        "    \"\"\"\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit_transform(token_pairs)\n",
        "    return vectorizer, X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00082e8d",
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorizer, X = vectorize(augmented_token_pairs)\n",
        "Y = augmented_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "98481ef1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (2733, 2460)\n"
          ]
        }
      ],
      "source": [
        "print(f\"X shape: {X.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da83cb61",
      "metadata": {},
      "source": [
        "## Separación del Conjunto de Datos y Balanceo de Clases\n",
        "Antes de entrenar el modelo, se transformó la matriz TF-IDF dispersa a una representación densa (X_dense) para su uso en ciertos algoritmos que no aceptan matrices dispersas.\n",
        "\n",
        "Posteriormente, el conjunto de datos fue dividido en entrenamiento y prueba utilizando muestreo estratificado, lo cual garantiza que la distribución de clases (por ejemplo, plagio vs. no plagio) se mantenga proporcional en ambos subconjuntos. Esto es crucial cuando se trabaja con clases desbalanceadas.\n",
        "\n",
        "A pesar de esto, el conjunto de entrenamiento seguía mostrando un desbalance significativo, por lo que se aplicó SMOTE (Synthetic Minority Over-sampling Technique). Esta técnica genera ejemplos sintéticos de la clase minoritaria a partir de instancias existentes, incrementando así su representación sin necesidad de duplicar ejemplos reales. El resultado fue un conjunto de entrenamiento balanceado, lo cual mejora la capacidad del modelo para aprender correctamente ambas clases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "016412c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_dense = X.toarray()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_dense, Y, test_size=0.2, random_state=42, stratify=Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d20b5a8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set class distribution:\n",
            "Label 0: 1584 samples (72.46%)\n",
            "Label 1: 602 samples (27.54%)\n",
            "\n",
            "Resampled training set class distribution:\n",
            "Label 0: 1584 samples (50.00%)\n",
            "Label 1: 1584 samples (50.00%)\n"
          ]
        }
      ],
      "source": [
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(f\"Training set class distribution:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Label {label}: {count} samples ({count/len(y_train)*100:.2f}%)\")\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "unique, counts = np.unique(y_train_resampled, return_counts=True)\n",
        "print(f\"\\nResampled training set class distribution:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Label {label}: {count} samples ({count/len(y_train_resampled)*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ad62b9a",
      "metadata": {},
      "source": [
        "## Función para calcular la matriz de confusión\n",
        "Esta función calcula la cantidad de True Positives (TP), True Negatives (TN), False Positives (FP) y False Negatives (FN). A partir de estas tasas de predicciones correctas e incorrectas podemos calcular las métricas de F1, precision y recall, lo cual nos dará un mejor output sobre el ajuste y rendimiento predictivo del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "bdf66f8b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calcular_matriz_confusion(y_true, y_pred):\n",
        "    TP = TN = FP = FN = 0\n",
        "\n",
        "    for i in range(len(y_pred)):\n",
        "        if y_pred[i] == 1:\n",
        "            if y_true[i] == 1:\n",
        "                TP += 1\n",
        "            else:\n",
        "                FP += 1\n",
        "        else:\n",
        "            if y_true[i] == 0:\n",
        "                TN += 1\n",
        "            else:\n",
        "                FN += 1\n",
        "\n",
        "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "    print(\"\\nTP:\", TP)\n",
        "    print(\"TN:\", TN)\n",
        "    print(\"FP:\", FP)\n",
        "    print(\"FN:\", FN)\n",
        "    print(f\"Precisión: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "    return precision, recall, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28d9b773",
      "metadata": {},
      "source": [
        "## Función  para evaluar el modelo\n",
        "Declaración de la función evaluate_model para evaluar al modelo una vez terminado el entrenamiento para ver su capacidad predictiva con datos que no fueron vistos durante el entrenamiento. Al terminar la evaluación obtenemos las métricas (precision, recall, f1 y accuracy) para determinar el ajuste y rendimiento del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1405f2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(name, model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(f\"\\nMatriz de confusión para {name}:\")\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(cm)\n",
        "    precision, recall, f1 = calcular_matriz_confusion(y_test, y_pred)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'name': name,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b9558a2",
      "metadata": {},
      "source": [
        "## Definición del modelo y entrenamiento\n",
        "Para encontrar la mejor arquitectura que se adecúe a la problemática, hemos decidido utilizar tres arquitecturas diferentes con el fin de comparar sus métricas y así tener la suficiente información como para tomar una decisión basada en los datos. Para identificar el modelo más adecuado al problema de detección de plagio, se entrenaron y compararon los siguientes clasificadores:\n",
        "\n",
        "- Logistic Regression (LR): Modelo lineal utilizado para clasificación binaria. Calcula la probabilidad de pertenencia a una clase usando la función sigmoide. Es sencillo, rápido y efectivo para problemas linealmente separables.\n",
        "\n",
        "- Random Forest (RF): Ensamble de múltiples árboles de decisión entrenados sobre diferentes subconjuntos del conjunto de datos. Es robusto, reduce el sobreajuste y suele ofrecer un buen rendimiento general en tareas de clasificación.\n",
        "\n",
        "- Multi-layer Perceptron (MLP): Red neuronal completamente conectada con al menos una capa oculta. Puede modelar relaciones no lineales complejas entre características y clases. En este caso, se utiliza una arquitectura básica con una sola capa oculta de 100 neuronas y función de activación ReLU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76462cff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# dt_model = DecisionTreeClassifier()\n",
        "\n",
        "# svm_model = SVC()\n",
        "\n",
        "# nb_model = GaussianNB()\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "mlp_model = MLPClassifier(hidden_layer_sizes=(100,), \n",
        "                          activation='relu',          \n",
        "                          solver='adam',             \n",
        "                          max_iter=300,              \n",
        "                          random_state=42)            \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "804bdc11",
      "metadata": {},
      "outputs": [],
      "source": [
        "base_models = [\n",
        "    # ('DT', dt_model),\n",
        "    # ('SVM', svm_model),\n",
        "    # ('NB', nb_model),\n",
        "    ('LR', lr_model),\n",
        "    ('RF', rf_model),\n",
        "    ('MLP', mlp_model),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7b4000c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DT: Accuracy = 0.9334, Desviación =  0.0162\n",
            "SVM: Accuracy = 0.7989, Desviación =  0.0156\n",
            "NB: Accuracy = 0.9293, Desviación =  0.0115\n",
            "LR: Accuracy = 0.7857, Desviación =  0.0204\n",
            "RF: Accuracy = 0.9836, Desviación =  0.0074\n"
          ]
        }
      ],
      "source": [
        "for name, model in base_models:\n",
        "    cv_scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=10, scoring='accuracy')\n",
        "    print(f\"{name}: Accuracy = {cv_scores.mean():.4f}, Desviación =  {cv_scores.std():.4f}\")\n",
        "    model.fit(X_train_resampled, y_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47c20f29",
      "metadata": {},
      "outputs": [],
      "source": [
        "results = {\n",
        "    'Model': [],\n",
        "    'Accuracy': [],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'F1-Score': [],\n",
        "}\n",
        "\n",
        "roc_curves = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "aa78986e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluación de DT\n",
            "\n",
            "Matriz de confusión para DT:\n",
            "\n",
            "TP: 143\n",
            "TN: 366\n",
            "FP: 30\n",
            "FN: 8\n",
            "Precisión: 0.8266\n",
            "Recall: 0.9470\n",
            "F1-Score: 0.8827\n",
            "Accuracy: 0.9305\n",
            "\n",
            "Evaluación de SVM\n",
            "\n",
            "Matriz de confusión para SVM:\n",
            "\n",
            "TP: 99\n",
            "TN: 345\n",
            "FP: 51\n",
            "FN: 52\n",
            "Precisión: 0.6600\n",
            "Recall: 0.6556\n",
            "F1-Score: 0.6578\n",
            "Accuracy: 0.8117\n",
            "\n",
            "Evaluación de NB\n",
            "\n",
            "Matriz de confusión para NB:\n",
            "\n",
            "TP: 151\n",
            "TN: 344\n",
            "FP: 52\n",
            "FN: 0\n",
            "Precisión: 0.7438\n",
            "Recall: 1.0000\n",
            "F1-Score: 0.8531\n",
            "Accuracy: 0.9049\n",
            "\n",
            "Evaluación de LR\n",
            "\n",
            "Matriz de confusión para LR:\n",
            "\n",
            "TP: 110\n",
            "TN: 320\n",
            "FP: 76\n",
            "FN: 41\n",
            "Precisión: 0.5914\n",
            "Recall: 0.7285\n",
            "F1-Score: 0.6528\n",
            "Accuracy: 0.7861\n",
            "\n",
            "Evaluación de RF\n",
            "\n",
            "Matriz de confusión para RF:\n",
            "\n",
            "TP: 145\n",
            "TN: 395\n",
            "FP: 1\n",
            "FN: 6\n",
            "Precisión: 0.9932\n",
            "Recall: 0.9603\n",
            "F1-Score: 0.9764\n",
            "Accuracy: 0.9872\n"
          ]
        }
      ],
      "source": [
        "for name, model in base_models:\n",
        "    print(f\"\\nEvaluación de {name}\")\n",
        "    model.fit(X_train_resampled, y_train_resampled)\n",
        "    result = evaluate_model(name, model, X_test, y_test)\n",
        "    results['Model'].append(name)\n",
        "    results['Accuracy'].append(result['accuracy'])\n",
        "    results['Precision'].append(result['precision'])\n",
        "    results['Recall'].append(result['recall'])\n",
        "    results['F1-Score'].append(result['f1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "cc423479",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model               Accuracy  Precision Recall    F1-Score  \n",
            "DT                  0.9305    0.8266    0.9470    0.8827    \n",
            "SVM                 0.8117    0.6600    0.6556    0.6578    \n",
            "NB                  0.9049    0.7438    1.0000    0.8531    \n",
            "LR                  0.7861    0.5914    0.7285    0.6528    \n",
            "RF                  0.9872    0.9932    0.9603    0.9764    \n"
          ]
        }
      ],
      "source": [
        "print(f\"{'Model':<20}{'Accuracy':<10}{'Precision':<10}{'Recall':<10}{'F1-Score':<10}\")\n",
        "for i in range(len(results['Model'])):\n",
        "    print(f\"{results['Model'][i]:<20}{results['Accuracy'][i]:<10.4f}{results['Precision'][i]:<10.4f}{results['Recall'][i]:<10.4f}{results['F1-Score'][i]:<10.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b23eb9d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import cross_validate\n",
        "# from sklearn.ensemble import VotingClassifier\n",
        "# from sklearn.model_selection import train_test_split, KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f3d6161",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados de la validación cruzada (k=5) para el modelo propuesto:\n",
            "Accuracy: 96.05%\n",
            "Precision: 95.80%\n",
            "Sensitivity: 96.34%\n",
            "F1-Score: 96.06%\n"
          ]
        }
      ],
      "source": [
        "# voting_model_final = VotingClassifier(estimators=base_models, voting='hard')\n",
        "\n",
        "# kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# scoring = {\n",
        "#     'accuracy': 'accuracy',\n",
        "#     'precision': 'precision',\n",
        "#     'recall': 'recall',\n",
        "#     'f1': 'f1',\n",
        "# }\n",
        "\n",
        "# cv_results = cross_validate(voting_model_final, X_train_resampled, y_train_resampled, cv=kfold, scoring=scoring, return_estimator=True)\n",
        "\n",
        "# print(\"\\nResultados de la validación cruzada (k=5) para el modelo propuesto:\")\n",
        "# print(f\"Accuracy: {cv_results['test_accuracy'].mean()*100:.2f}%\")\n",
        "# print(f\"Precision: {cv_results['test_precision'].mean()*100:.2f}%\")\n",
        "# print(f\"Sensitivity: {cv_results['test_recall'].mean()*100:.2f}%\")\n",
        "# print(f\"F1-Score: {cv_results['test_f1'].mean()*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45da4f05",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Matriz de confusión para Ensemble Final:\n",
            "\n",
            "TP: 144\n",
            "TN: 376\n",
            "FP: 20\n",
            "FN: 7\n",
            "Precisión: 0.8780\n",
            "Recall: 0.9536\n",
            "F1-Score: 0.9143\n",
            "Accuracy: 0.9506\n",
            "Accuracy: 0.95%\n",
            "Precision: 0.88%\n",
            "Recall: 0.95%\n",
            "F1-Score: 0.91%\n"
          ]
        }
      ],
      "source": [
        "# voting_model_final.fit(X_train_resampled, y_train_resampled)\n",
        "# final_result = evaluate_model('Ensemble Final', voting_model_final, X_test, y_test)\n",
        "\n",
        "# print(f\"Accuracy: {final_result['accuracy']:.2f}%\")\n",
        "# print(f\"Precision: {final_result['precision']:.2f}%\")\n",
        "# print(f\"Recall: {final_result['recall']:.2f}%\")\n",
        "# print(f\"F1-Score: {final_result['f1']:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b25ad8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# dt_params = {\n",
        "#     'criterion': ['gini', 'entropy'],\n",
        "#     'max_depth': [None, 10, 20]\n",
        "# }\n",
        "\n",
        "# svm_params = {\n",
        "#     'C': [0.1, 1, 2.14355, 10],\n",
        "#     'kernel': ['linear', 'rbf']\n",
        "# }\n",
        "\n",
        "# nb_params = {\n",
        "#     'var_smoothing': [1e-10, 1e-9, 1e-8, 1e-7]\n",
        "# }\n",
        "\n",
        "# lr_params = {\n",
        "#     'C': [0.1, 1, 10],\n",
        "#     'penalty': ['l1', 'l2', None]\n",
        "# }\n",
        "\n",
        "# rf_params = {\n",
        "#     'n_estimators': [100, 150, 200],\n",
        "#     'max_depth': [None, 3, 4, 5, 10, 20],\n",
        "#     'min_samples_split': [5, 10, 20],\n",
        "#     'min_samples_leaf': [3, 5]\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e1bac36",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49ea300c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def refine_model(model, param_grid, X_train, y_train):\n",
        "#     model.fit(X_train, y_train)\n",
        "    \n",
        "#     grid = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "#     grid.fit(X_train, y_train)\n",
        "    \n",
        "#     refined_model = grid.best_estimator_\n",
        "    \n",
        "#     return refined_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "193de5c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def refine_all(X_train, y_train):\n",
        "#     dt = refine_model(\n",
        "#         DecisionTreeClassifier(random_state=42), \n",
        "#         dt_params, X_train, y_train)\n",
        "    \n",
        "#     svm = refine_model(\n",
        "#         SVC(probability=True, random_state=42), \n",
        "#         svm_params, X_train, y_train)\n",
        "    \n",
        "#     nb = refine_model(\n",
        "#         GaussianNB(), \n",
        "#         nb_params, X_train, y_train)\n",
        "    \n",
        "#     lr = refine_model(\n",
        "#         LogisticRegression(random_state=42, max_iter=1000), \n",
        "#         lr_params, X_train, y_train)\n",
        "    \n",
        "#     rf = refine_model(\n",
        "#         RandomForestClassifier(random_state=42), \n",
        "#         rf_params, X_train, y_train)\n",
        "    \n",
        "#     return {\n",
        "#         'DT': dt,\n",
        "#         'SVM': svm,\n",
        "#         'NB': nb,\n",
        "#         'LR': lr,\n",
        "#         'RF': rf\n",
        "#     }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3acad65",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "15 fits failed out of a total of 45.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 63, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan 0.76136718 0.94824056        nan 0.78283224 0.94824056\n",
            "        nan 0.86175091 0.94824056]\n",
            "  warnings.warn(\n",
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# refined_models = refine_all(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# base_models_final_refined = [\n",
        "#     ('DT', refined_models['DT']),\n",
        "#     ('SVM', refined_models['SVM']),\n",
        "#     ('NB', refined_models['NB']),\n",
        "#     ('LR', refined_models['LR']),\n",
        "#     ('RF', refined_models['RF'])\n",
        "# ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f255b728",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 97.19%\n",
            "Precision: 95.89%\n",
            "Sensitivity: 98.62%\n",
            "F1-Score: 97.22%\n"
          ]
        }
      ],
      "source": [
        "# # 29. Crear modelo final con sub modelos optimizados\n",
        "# voting_model_final_refined = VotingClassifier(estimators=base_models_final_refined, voting='hard')\n",
        "\n",
        "# # Configurar la validación cruzada como indica el paper\n",
        "# kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# scoring = {\n",
        "#     'accuracy': 'accuracy',\n",
        "#     'precision': 'precision',\n",
        "#     'recall': 'recall',\n",
        "#     'f1': 'f1',\n",
        "# }\n",
        "\n",
        "# cv_results = cross_validate(voting_model_final_refined, X_train_resampled, y_train_resampled, cv=kfold, scoring=scoring, return_estimator=True)\n",
        "\n",
        "# print(f\"Accuracy: {cv_results['test_accuracy'].mean()*100:.2f}%\")\n",
        "# print(f\"Precision: {cv_results['test_precision'].mean()*100:.2f}%\")\n",
        "# print(f\"Sensitivity: {cv_results['test_recall'].mean()*100:.2f}%\")\n",
        "# print(f\"F1-Score: {cv_results['test_f1'].mean()*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6d1b448",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Matriz de confusión para Ensemble Final:\n",
            "\n",
            "TP: 151\n",
            "TN: 381\n",
            "FP: 15\n",
            "FN: 0\n",
            "Precisión: 0.9096\n",
            "Recall: 1.0000\n",
            "F1-Score: 0.9527\n",
            "Accuracy: 0.9726\n",
            "Accuracy: 0.9726\n",
            "Precision: 0.9096\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'sensitivity'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_result[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrecision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_result[\u001b[33m'\u001b[39m\u001b[33mprecision\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSensitivity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mfinal_result\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msensitivity\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSpecificity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_result[\u001b[33m'\u001b[39m\u001b[33mspecificity\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mF1-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_result[\u001b[33m'\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mKeyError\u001b[39m: 'sensitivity'"
          ]
        }
      ],
      "source": [
        "# voting_model_final_refined.fit(X_train_resampled, y_train_resampled)\n",
        "# final_result = evaluate_model('Ensemble Final', voting_model_final_refined, X_test, y_test)\n",
        "\n",
        "# print(f\"Accuracy: {final_result['accuracy']:.4f}\")\n",
        "# print(f\"Precision: {final_result['precision']:.4f}\")\n",
        "# print(f\"Recall: {final_result['recall']:.4f}\")\n",
        "# print(f\"F1-Score: {final_result['f1']:.4f}\")\n",
        "# print(f\"MCC: {final_result['mcc']:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
