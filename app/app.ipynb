{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9eb6c7c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "from pygments import lex\n",
        "from pygments.lexers import JavaLexer\n",
        "from pygments.token import Token\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "20022a95",
      "metadata": {},
      "outputs": [],
      "source": [
        "ROOT = Path().cwd().parent\n",
        "BASE_PATH = ROOT / \"dataset\" / \"versions\" / \"bplag_version_2\"\n",
        "LABELS_PATH = ROOT / \"dataset\" / \"versions\" / \"labels.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ed95e47a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_java_files(base_path):\n",
        "    \"\"\"\n",
        "    Recursively reads all .java files from the given base path.\n",
        "    \n",
        "    Args:\n",
        "        base_path (str): Path to the base directory containing submission pairs.\n",
        "    \n",
        "    Returns:\n",
        "        data (list): List of tuples (submission_id, code_content).\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    \n",
        "    # Iterate over all submission pairs\n",
        "    for submission_pair in os.listdir(base_path):\n",
        "        pair_path = os.path.join(base_path, submission_pair)\n",
        "        \n",
        "        if os.path.isdir(pair_path):\n",
        "            # Iterate over each submission inside the pair\n",
        "            for submission_id in os.listdir(pair_path):\n",
        "                submission_path = os.path.join(pair_path, submission_id)\n",
        "                \n",
        "                if os.path.isdir(submission_path):\n",
        "                    # Look for .java files inside the submission directory\n",
        "                    for file in os.listdir(submission_path):\n",
        "                        if file.endswith('.java'):\n",
        "                            file_path = os.path.join(submission_path, file)\n",
        "                            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                                code = f.read()\n",
        "                                data.append((submission_id, code))\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bbcf8253",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total submissions loaded: 1822\n",
            "\n",
            "First 2 submissions loaded:\n",
            "Submission ID: 5756162d\n",
            "Code snippet:\n",
            "import java.util.*;\n",
            "import java.io.*;\n",
            "public class EdD {\n",
            "\tpublic static void main(String[] args) throws Exception{\n",
            "\t\tint num = 998244353;\n",
            "\n",
            "\t\t// TODO Auto-generated method stub\n",
            " \t\tBufferedReader bf = new BufferedReader(new InputStreamReader(System.in));\n",
            " \t\tPrintWriter out = new PrintWriter(System.out...\n",
            "\n",
            "Submission ID: 808f7516\n",
            "Code snippet:\n",
            "import java.io.*;\n",
            "import java.math.BigInteger;\n",
            "import java.util.*;\n",
            "\n",
            "public class Main {\n",
            "    static int MOD = 1000000007;\n",
            "\n",
            "    // After writing solution, quick scan for:\n",
            "    //   array out of bounds\n",
            "    //   special cases e.g. n=1?\n",
            "    //\n",
            "    // Big numbers arithmetic bugs:\n",
            "    //   int overflow\n",
            "    ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Read the Java files\n",
        "java_files_data = read_java_files(BASE_PATH)\n",
        "\n",
        "# Print the number of submissions loaded and the first few entries\n",
        "print(f\"Total submissions loaded: {len(java_files_data)}\")\n",
        "print(\"\\nFirst 2 submissions loaded:\")\n",
        "for submission_id, code in java_files_data[:2]:\n",
        "    print(f\"Submission ID: {submission_id}\\nCode snippet:\\n{code[:300]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26774854",
      "metadata": {},
      "source": [
        "## Extracción de tokens\n",
        "\n",
        "Para esta sección se utiliza la librería Pygments como analizador léxico. Esta librería permite extraer los tokens de un código fuente y clasificarlos en diferentes categorías. En este caso, se utilizará para extraer los tokens de código fuente en Java."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b981f462",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_tokens(code):\n",
        "    \"\"\"\n",
        "    Extracts tokens from the given Java code using Pygments.\n",
        "    \n",
        "    Args:\n",
        "        code (str): Java code as a string.\n",
        "        \n",
        "    Returns:\n",
        "        tokens (list): List of tokens extracted from the code.\n",
        "    \"\"\"\n",
        "    lexer = JavaLexer()\n",
        "    tokens = []\n",
        "    for ttype, value in lex(code, lexer):\n",
        "        if ttype in Token.Name or ttype in Token.Keyword or ttype in Token.Operator:\n",
        "            val = value.strip()\n",
        "            if val:\n",
        "                tokens.append(f\"{ttype.__class__.__name__}:{val}\")\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58bd1fbe",
      "metadata": {},
      "outputs": [],
      "source": [
        "labels_df = pd.read_csv(LABELS_PATH)\n",
        "\n",
        "labels_dict = {}\n",
        "for _, row in labels_df.iterrows():\n",
        "    key = (row['sub1'], row['sub2'])\n",
        "    labels_dict[key] = row['verdict']\n",
        "\n",
        "token_pairs = []\n",
        "labels = []\n",
        "\n",
        "for i in range(0, len(java_files_data), 2):\n",
        "    try:\n",
        "        id1, code1 = java_files_data[i]\n",
        "        id2, code2 = java_files_data[i+1]\n",
        "    except IndexError:\n",
        "        break\n",
        "        \n",
        "    t1 = extract_tokens(code1)\n",
        "    t2 = extract_tokens(code2)\n",
        "    token_pairs.append(f\"{t1} {t2}\")\n",
        "    \n",
        "    if (id1, id2) in labels_dict:\n",
        "        labels.append(labels_dict[(id1, id2)])\n",
        "    elif (id2, id1) in labels_dict:\n",
        "        labels.append(labels_dict[(id2, id1)])\n",
        "    else:\n",
        "        print(f\"Warning: No label found for pair ({id1}, {id2})\")\n",
        "        labels.append(0) \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5025b334",
      "metadata": {},
      "source": [
        "## Vectorización de tokens\n",
        "\n",
        "Para la vectorización de los tokens, se utilizará la librería Scikit-learn. Esta librería permite transformar los tokens extraídos en vectores numéricos que pueden ser utilizados como entrada para el modelo. En este caso, se utilizará el método `TfidfVectorizer` para transformar los tokens en vectores numéricos. Este método asigna un peso a cada token en función de su frecuencia en el documento y su frecuencia en el corpus. Esto permite que los tokens más relevantes tengan un mayor peso en el vector resultante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e75ae232",
      "metadata": {},
      "outputs": [],
      "source": [
        "def vectorize(token_pairs):\n",
        "    \"\"\"\n",
        "    Vectorizes the given token pairs using TF-IDF.\n",
        "    \n",
        "    Args:\n",
        "        token_pairs (list): List of tokens to be vectorized.\n",
        "    \n",
        "    Returns:\n",
        "        vectorizer (TfidfVectorizer): Fitted TF-IDF vectorizer.\n",
        "        X (sparse matrix): TF-IDF matrix of the token pairs.\n",
        "        Y (list): Labels corresponding to the token pairs.\n",
        "    \"\"\"\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit_transform(token_pairs)\n",
        "    Y = labels\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00082e8d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vectorized data shape: (911, 2456)\n",
            "First 2 labels: [1, 0]\n"
          ]
        }
      ],
      "source": [
        "X, Y = vectorize(token_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "98481ef1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 56328 stored elements and shape (911, 2456)>\n",
            "  Coords\tValues\n",
            "  (0, 17)\t0.9806028213497687\n",
            "  (0, 940)\t0.004035402556994933\n",
            "  (0, 1053)\t0.004035402556994933\n",
            "  (0, 2342)\t0.001615931907257326\n",
            "  (0, 1019)\t0.0017183365880872636\n",
            "  (0, 1792)\t0.0032283220455959463\n",
            "  (0, 345)\t0.0016141610227979732\n",
            "  (0, 644)\t0.005421182152332093\n",
            "  (0, 2087)\t0.00242124153419696\n",
            "  (0, 2373)\t0.0032283220455959463\n",
            "  (0, 1214)\t0.004035402556994933\n",
            "  (0, 2109)\t0.0016141610227979732\n",
            "  (0, 116)\t0.0016194795153288493\n",
            "  (0, 2243)\t0.0067821059137036024\n",
            "  (0, 703)\t0.001612973670251707\n",
            "  (0, 993)\t0.04761775017254021\n",
            "  (0, 1501)\t0.0029900445395058374\n",
            "  (0, 228)\t0.005501618137342144\n",
            "  (0, 179)\t0.012713190242901008\n",
            "  (0, 1413)\t0.021791173807772637\n",
            "  (0, 990)\t0.002750809068671072\n",
            "  (0, 2168)\t0.0032283220455959463\n",
            "  (0, 941)\t0.001960253080026935\n",
            "  (0, 1772)\t0.004926175442304638\n",
            "  (0, 1620)\t0.0040398297681433154\n",
            "  :\t:\n",
            "  (910, 1956)\t0.006072492475820603\n",
            "  (910, 1952)\t0.013415506453166744\n",
            "  (910, 1441)\t0.0077547072379126275\n",
            "  (910, 2079)\t0.017833356189198138\n",
            "  (910, 95)\t0.016098607743800092\n",
            "  (910, 1951)\t0.025491221871263618\n",
            "  (910, 110)\t0.021802624829915514\n",
            "  (910, 1756)\t0.007685230565331937\n",
            "  (910, 645)\t0.04459489780431515\n",
            "  (910, 2112)\t0.008459540166269862\n",
            "  (910, 1646)\t0.023436646872575715\n",
            "  (910, 423)\t0.00921195189035652\n",
            "  (910, 1867)\t0.01984660235207392\n",
            "  (910, 1776)\t0.01811842825212116\n",
            "  (910, 2351)\t0.028828502631409507\n",
            "  (910, 2303)\t0.022297448902157575\n",
            "  (910, 2056)\t0.005923668299129056\n",
            "  (910, 927)\t0.013012676524637085\n",
            "  (910, 565)\t0.0330185505916129\n",
            "  (910, 2355)\t0.01793997555736918\n",
            "  (910, 2252)\t0.013506458692382189\n",
            "  (910, 831)\t0.03269813694240489\n",
            "  (910, 552)\t0.037447496678011595\n",
            "  (910, 1526)\t0.03387379611485983\n",
            "  (910, 2354)\t0.03538948440267655\n"
          ]
        }
      ],
      "source": [
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "aadfa1e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "bdf66f8b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calcular_matriz_confusion(y_true, y_pred):\n",
        "    TP = TN = FP = FN = 0\n",
        "\n",
        "    for i in range(len(y_pred)):\n",
        "        if y_pred[i] == 1:\n",
        "            if y_true[i] == 1:\n",
        "                TP += 1\n",
        "            else:\n",
        "                FP += 1\n",
        "        else:\n",
        "            if y_true[i] == 0:\n",
        "                TN += 1\n",
        "            else:\n",
        "                FN += 1\n",
        "\n",
        "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "    print(\"\\nTP:\", TP)\n",
        "    print(\"TN:\", TN)\n",
        "    print(\"FP:\", FP)\n",
        "    print(\"FN:\", FN)\n",
        "    print(f\"Precisión: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "    return precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d1405f2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(name, model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(f\"\\nMatriz de confusión para {name}:\")\n",
        "    precision, recall, f1 = calcular_matriz_confusion(y_test, y_pred)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'name': name,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "00de3cfe",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_dense = X.toarray()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_dense, Y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "29eefda6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "% class: 27.75%\n",
            "% class: 50.00%\n"
          ]
        }
      ],
      "source": [
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(f\"% class: {np.min(counts)/sum(counts)*100:.2f}%\")\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "unique, counts = np.unique(y_train_resampled, return_counts=True)\n",
        "print(f\"% class: {np.min(counts)/sum(counts)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "76462cff",
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_model = DecisionTreeClassifier()\n",
        "\n",
        "svm_model = SVC()\n",
        "\n",
        "nb_model = GaussianNB()\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "rf_model = RandomForestClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "804bdc11",
      "metadata": {},
      "outputs": [],
      "source": [
        "base_models = [\n",
        "    ('DT', dt_model),\n",
        "    ('SVM', svm_model),\n",
        "    ('NB', nb_model),\n",
        "    ('LR', lr_model),\n",
        "    ('RF', rf_model)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "d7b4000c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DT: Accuracy = 0.8205, Desviación =  0.0819\n",
            "SVM: Accuracy = 0.6207, Desviación =  0.0364\n",
            "NB: Accuracy = 0.8764, Desviación =  0.0208\n",
            "LR: Accuracy = 0.7872, Desviación =  0.0699\n",
            "RF: Accuracy = 0.8927, Desviación =  0.0681\n"
          ]
        }
      ],
      "source": [
        "for name, model in base_models:\n",
        "    cv_scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=10, scoring='accuracy')\n",
        "    print(f\"{name}: Accuracy = {cv_scores.mean():.4f}, Desviación =  {cv_scores.std():.4f}\")\n",
        "    model.fit(X_train_resampled, y_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "47c20f29",
      "metadata": {},
      "outputs": [],
      "source": [
        "results = {\n",
        "    'Model': [],\n",
        "    'Accuracy': [],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'F1-Score': [],\n",
        "    'AUC-ROC': []\n",
        "}\n",
        "\n",
        "roc_curves = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "aa78986e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluación de DT\n",
            "\n",
            "Matriz de confusión para DT:\n",
            "\n",
            "TP: 28\n",
            "TN: 101\n",
            "FP: 33\n",
            "FN: 21\n",
            "Precisión: 0.4590\n",
            "Recall: 0.5714\n",
            "F1-Score: 0.5091\n",
            "Accuracy: 0.7049\n",
            "\n",
            "Evaluación de SVM\n",
            "\n",
            "Matriz de confusión para SVM:\n",
            "\n",
            "TP: 8\n",
            "TN: 130\n",
            "FP: 4\n",
            "FN: 41\n",
            "Precisión: 0.6667\n",
            "Recall: 0.1633\n",
            "F1-Score: 0.2623\n",
            "Accuracy: 0.7541\n",
            "\n",
            "Evaluación de NB\n",
            "\n",
            "Matriz de confusión para NB:\n",
            "\n",
            "TP: 24\n",
            "TN: 107\n",
            "FP: 27\n",
            "FN: 25\n",
            "Precisión: 0.4706\n",
            "Recall: 0.4898\n",
            "F1-Score: 0.4800\n",
            "Accuracy: 0.7158\n",
            "\n",
            "Evaluación de LR\n",
            "\n",
            "Matriz de confusión para LR:\n",
            "\n",
            "TP: 21\n",
            "TN: 109\n",
            "FP: 25\n",
            "FN: 28\n",
            "Precisión: 0.4565\n",
            "Recall: 0.4286\n",
            "F1-Score: 0.4421\n",
            "Accuracy: 0.7104\n",
            "\n",
            "Evaluación de RF\n",
            "\n",
            "Matriz de confusión para RF:\n",
            "\n",
            "TP: 21\n",
            "TN: 122\n",
            "FP: 12\n",
            "FN: 28\n",
            "Precisión: 0.6364\n",
            "Recall: 0.4286\n",
            "F1-Score: 0.5122\n",
            "Accuracy: 0.7814\n"
          ]
        }
      ],
      "source": [
        "for name, model in base_models:\n",
        "    print(f\"\\nEvaluación de {name}\")\n",
        "    model.fit(X_train_resampled, y_train_resampled)\n",
        "    result = evaluate_model(name, model, X_test, y_test)\n",
        "    results['Model'].append(name)\n",
        "    results['Accuracy'].append(result['accuracy'])\n",
        "    results['Precision'].append(result['precision'])\n",
        "    results['Recall'].append(result['recall'])\n",
        "    results['F1-Score'].append(result['f1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "cc423479",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model               Accuracy  Precision Recall    F1-Score  \n",
            "DT                  0.7049    0.4590    0.5714    0.5091    \n",
            "SVM                 0.7541    0.6667    0.1633    0.2623    \n",
            "NB                  0.7158    0.4706    0.4898    0.4800    \n",
            "LR                  0.7104    0.4565    0.4286    0.4421    \n",
            "RF                  0.7814    0.6364    0.4286    0.5122    \n"
          ]
        }
      ],
      "source": [
        "print(f\"{'Model':<20}{'Accuracy':<10}{'Precision':<10}{'Recall':<10}{'F1-Score':<10}\")\n",
        "for i in range(len(results['Model'])):\n",
        "    print(f\"{results['Model'][i]:<20}{results['Accuracy'][i]:<10.4f}{results['Precision'][i]:<10.4f}{results['Recall'][i]:<10.4f}{results['F1-Score'][i]:<10.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "b23eb9d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import train_test_split, KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "6f3d6161",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados de la validación cruzada (k=5) para el modelo propuesto:\n",
            "Accuracy: 84.51%\n",
            "Precision: 92.23%\n",
            "Sensitivity: 75.46%\n",
            "F1-Score: 82.96%\n"
          ]
        }
      ],
      "source": [
        "voting_model_final = VotingClassifier(estimators=base_models, voting='hard')\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'f1': 'f1',\n",
        "}\n",
        "\n",
        "cv_results = cross_validate(voting_model_final, X_train_resampled, y_train_resampled, cv=kfold, scoring=scoring, return_estimator=True)\n",
        "\n",
        "print(\"\\nResultados de la validación cruzada (k=5) para el modelo propuesto:\")\n",
        "print(f\"Accuracy: {cv_results['test_accuracy'].mean()*100:.2f}%\")\n",
        "print(f\"Precision: {cv_results['test_precision'].mean()*100:.2f}%\")\n",
        "print(f\"Sensitivity: {cv_results['test_recall'].mean()*100:.2f}%\")\n",
        "print(f\"F1-Score: {cv_results['test_f1'].mean()*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "45da4f05",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Matriz de confusión para Ensemble Final:\n",
            "\n",
            "TP: 15\n",
            "TN: 123\n",
            "FP: 11\n",
            "FN: 34\n",
            "Precisión: 0.5769\n",
            "Recall: 0.3061\n",
            "F1-Score: 0.4000\n",
            "Accuracy: 0.7541\n",
            "Accuracy: 0.75%\n",
            "Precision: 0.58%\n",
            "Recall: 0.31%\n",
            "F1-Score: 0.40%\n"
          ]
        }
      ],
      "source": [
        "voting_model_final.fit(X_train_resampled, y_train_resampled)\n",
        "final_result = evaluate_model('Ensemble Final', voting_model_final, X_test, y_test)\n",
        "\n",
        "print(f\"Accuracy: {final_result['accuracy']:.2f}%\")\n",
        "print(f\"Precision: {final_result['precision']:.2f}%\")\n",
        "print(f\"Recall: {final_result['recall']:.2f}%\")\n",
        "print(f\"F1-Score: {final_result['f1']:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "a2f8dd9a2b65164a0dd37b4e5739f150314b1e17efbbfa1422ea4f2e7b18b306"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
