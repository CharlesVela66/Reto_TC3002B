{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b95bc34f",
      "metadata": {},
      "source": [
        "# Detector de plagio en código fuente (archivos .java)\n",
        "Este notebook presenta el desarrollo de un modelo para detectar plagio en archivos de código fuente escritos en Java. Se utiliza el dataset \"conplag\", ubicado en   `dataset/versions/b_plag_version_2`, el cual contiene carpetas con archivos originales y versiones plagiadas.\n",
        "\n",
        "## Objetivo\n",
        "Desarrollar una herramienta híbrida automatizada que detecte plagio en código fuente, combinando análisis léxico (tokenización) y técnicas de aprendizaje automático. El objetivo es alcanzar una precisión superior al 80% en la clasificación de código como plagiado o no plagiado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1ee15c5",
      "metadata": {},
      "source": [
        "## Importación de librerías\n",
        "Se importan las librerías necesarias para el procesamiento de archivos, tokenización de código Java, manipulación de datos y desarrollo del modelo de machine learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9eb6c7c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from pygments import lex\n",
        "from pygments.lexers import JavaLexer\n",
        "from pygments.token import Token\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from collections import Counter\n",
        "from scipy.spatial.distance import cosine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00fd81c2",
      "metadata": {},
      "source": [
        "## Definición de rutas\n",
        "Se definen las rutas base para acceder al dataset y a los archivos de etiquetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "20022a95",
      "metadata": {},
      "outputs": [],
      "source": [
        "ROOT = Path().cwd().parent\n",
        "BASE_PATH = ROOT / \"dataset\" / \"versions\" / \"bplag_version_2\"\n",
        "LABELS_PATH = ROOT / \"dataset\" / \"versions\" / \"labels.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec18c12",
      "metadata": {},
      "source": [
        "## Lectura de archivos .java\n",
        "La función read_java_files() se encarga de recorrer recursivamente la estructura del dataset y leer el contenido de todos los archivos .java. Devuelve una lista con los identificadores de cada entrega y su respectivo código fuente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ed95e47a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_java_files(base_path):\n",
        "    \"\"\"\n",
        "    Recursively reads all .java files from the given base path.\n",
        "    \n",
        "    Args:\n",
        "        base_path (str): Path to the base directory containing submission pairs.\n",
        "    \n",
        "    Returns:\n",
        "        data (list): List of tuples (submission_id, code_content).\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    \n",
        "    for submission_pair in os.listdir(base_path):\n",
        "        pair_path = os.path.join(base_path, submission_pair)\n",
        "        \n",
        "        if os.path.isdir(pair_path):\n",
        "            for submission_id in os.listdir(pair_path):\n",
        "                submission_path = os.path.join(pair_path, submission_id)\n",
        "                \n",
        "                if os.path.isdir(submission_path):\n",
        "                    for file in os.listdir(submission_path):\n",
        "                        if file.endswith('.java'):\n",
        "                            file_path = os.path.join(submission_path, file)\n",
        "                            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                                code = f.read()\n",
        "                                data.append((submission_id, code))\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bbcf8253",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total submissions loaded: 1822\n",
            "\n",
            "First 2 submissions loaded:\n",
            "Submission ID: 0017d438\n",
            "Code snippet:\n",
            "import java.io.BufferedReader;\n",
            "import java.io.DataInputStream;\n",
            "import java.io.IOException;\n",
            "import java.io.InputStreamReader;\n",
            "import java.util.*;\n",
            "public class Main {\n",
            "    static int modulo=998244353;\n",
            "    public static void main(String[] args) {\n",
            "       \n",
            "        FastScanner in = new FastScanner();\n",
            "     ...\n",
            "\n",
            "Submission ID: 9852706b\n",
            "Code snippet:\n",
            "import java.io.BufferedReader;\n",
            "import java.io.IOException;\n",
            "import java.io.InputStreamReader;\n",
            "import java.io.PrintWriter;\n",
            "import java.util.*;\n",
            "\n",
            "public class A {\n",
            "    static List<Integer> [] adj;\n",
            "    static ArrayList<Integer> temp;\n",
            "    static int mod = (int) 1e9+7;\n",
            "    static boolean[] vis = new boolean...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "java_files_data = read_java_files(BASE_PATH)\n",
        "\n",
        "print(f\"Total submissions loaded: {len(java_files_data)}\")\n",
        "print(\"\\nFirst 2 submissions loaded:\")\n",
        "for submission_id, code in java_files_data[:2]:\n",
        "    print(f\"Submission ID: {submission_id}\\nCode snippet:\\n{code[:300]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26774854",
      "metadata": {},
      "source": [
        "## Extracción de tokens\n",
        "\n",
        "Para esta sección se utiliza la librería Pygments como analizador léxico. Esta librería permite extraer los tokens de un código fuente y clasificarlos en diferentes categorías. En este caso, se utilizará para extraer los tokens de código fuente en Java."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b981f462",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_tokens(code):\n",
        "    \"\"\"\n",
        "    Extracts tokens from the given Java code using Pygments.\n",
        "    \n",
        "    Args:\n",
        "        code (str): Java code as a string.\n",
        "        \n",
        "    Returns:\n",
        "        tokens (list): List of tokens extracted from the code.\n",
        "    \"\"\"\n",
        "    lexer = JavaLexer()\n",
        "    tokens = []\n",
        "    for ttype, value in lex(code, lexer):\n",
        "        if ttype in Token.Name or ttype in Token.Keyword or ttype in Token.Operator:\n",
        "            val = value.strip()\n",
        "            if val:\n",
        "                tokens.append(f\"{ttype.__class__.__name__}:{val}\")\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e2a1089",
      "metadata": {},
      "source": [
        "## Preparación de los datos y etiquetas\n",
        "Se cargan las etiquetas desde el archivo labels.csv y se construye un diccionario para acceder fácilmente al veredicto (si un archivo es plagio o no) entre pares de entregas.\n",
        "\n",
        "Luego, se recorren los datos de código Java en pares, extrayendo los tokens de cada archivo y concatenándolos como una sola representación textual del par. \n",
        "\n",
        "Paralelamente, se asigna la etiqueta correspondiente (plagiado o no) a cada par utilizando el diccionario previamente generado.\n",
        "\n",
        "Este proceso genera dos listas:\n",
        "\n",
        "- token_pairs: Representación textual de los pares de código.\n",
        "\n",
        "- labels: Etiquetas binarias que indican si el par es plagiado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "275f57de",
      "metadata": {},
      "outputs": [],
      "source": [
        "labels_df = pd.read_csv(LABELS_PATH)\n",
        "\n",
        "labels_dict = {}\n",
        "for _, row in labels_df.iterrows():\n",
        "    key = (row['sub1'], row['sub2'])\n",
        "    labels_dict[key] = row['verdict']\n",
        "\n",
        "token_pairs = []\n",
        "labels = []\n",
        "\n",
        "for i in range(0, len(java_files_data), 2):\n",
        "    try:\n",
        "        id1, code1 = java_files_data[i]\n",
        "        id2, code2 = java_files_data[i+1]\n",
        "    except IndexError:\n",
        "        break\n",
        "        \n",
        "    t1 = extract_tokens(code1)\n",
        "    t2 = extract_tokens(code2)\n",
        "    token_pairs.append(f\"{t1} {t2}\")\n",
        "    \n",
        "    if (id1, id2) in labels_dict:\n",
        "        labels.append(labels_dict[(id1, id2)])\n",
        "    elif (id2, id1) in labels_dict:\n",
        "        labels.append(labels_dict[(id2, id1)])\n",
        "    else:\n",
        "        print(f\"Warning: No label found for pair ({id1}, {id2})\")\n",
        "        labels.append(0) \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c631ae1a",
      "metadata": {},
      "source": [
        "## Data Augmentation\n",
        "Debido a que nuestro dataset original contenía menos de 1000 pares de código, el modelo tenía una exposición limitada a ejemplos variados, lo que afectaba negativamente su capacidad de generalización y su rendimiento predictivo. Para mitigar este problema, implementamos una estrategia de aumento de datos que multiplicó el tamaño del conjunto original por 3 veces.\n",
        "\n",
        "La función augment_token_sequence() permite generar nuevas versiones sintéticas de los pares de tokens aplicando pequeñas modificaciones controladas, lo que introduce variabilidad sin alterar significativamente la lógica del código original. Estas son las técnicas utilizadas:\n",
        "\n",
        "- Shuffle: Mezcla aleatoriamente grupos de tokens dentro de una ventana, simulando cambios menores en el orden del código que pueden aparecer en plagios.\n",
        "\n",
        "- Drop: Elimina tokens no críticos de forma aleatoria, simulando la omisión intencional de fragmentos para disimular el plagio.\n",
        "\n",
        "- Duplicate: Duplica tokens aleatoriamente para emular redundancias introducidas deliberadamente por quien plagia.\n",
        "\n",
        "- Synonym: Sustituye variables por sinónimos simulados (e.g., i por index), representando un cambio común en plagios superficiales.\n",
        "\n",
        "Estas transformaciones ayudan a enriquecer el entrenamiento del modelo, exponiéndolo a variaciones más realistas en los datos y mejorando su capacidad para identificar plagio con mayor precisión.\n",
        "\n",
        "La función generate_augmented_pairs() une los nuevos pares de tokens generados por la aumentación y les asigna las etiquetas correspondientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "99972272",
      "metadata": {},
      "outputs": [],
      "source": [
        "def augment_token_sequence(tokens, augmentation_method='shuffle', ratio=0.1):\n",
        "    \"\"\"\n",
        "    Augments a token sequence using various methods.\n",
        "    \n",
        "    Args:\n",
        "        tokens (str): The token sequence string to be augmented.\n",
        "        augmentation_method (str): The method to use for augmentation.\n",
        "            'shuffle': Randomly shuffles some tokens within a window.\n",
        "            'drop': Randomly drops some tokens.\n",
        "            'duplicate': Duplicates some tokens.\n",
        "            'synonym': Replaces some tokens with synonyms (simulated).\n",
        "        ratio (float): The percentage of tokens to modify (0.0 to 1.0).\n",
        "    \n",
        "    Returns:\n",
        "        str: The augmented token sequence as a string.\n",
        "    \"\"\"\n",
        "    token_list = tokens.split()\n",
        "    total_tokens = len(token_list)\n",
        "    num_to_modify = max(1, int(total_tokens * ratio))\n",
        "    \n",
        "    augmented_tokens = token_list.copy()\n",
        "    \n",
        "    if augmentation_method == 'shuffle':\n",
        "        for _ in range(num_to_modify // 2): \n",
        "            window_size = random.randint(2, 4) \n",
        "            if total_tokens <= window_size:\n",
        "                continue\n",
        "                \n",
        "            start_idx = random.randint(0, total_tokens - window_size)\n",
        "            window = augmented_tokens[start_idx:start_idx + window_size]\n",
        "            random.shuffle(window)\n",
        "            augmented_tokens[start_idx:start_idx + window_size] = window\n",
        "    \n",
        "    elif augmentation_method == 'drop':\n",
        "        critical_tokens = ['_TokenType:public', '_TokenType:class', '_TokenType:import', '_TokenType:static', '_TokenType:void', '_TokenType:main']\n",
        "        indices_to_drop = []\n",
        "        \n",
        "        for _ in range(num_to_modify):\n",
        "            valid_indices = [i for i, token in enumerate(augmented_tokens) \n",
        "                            if token not in critical_tokens and i not in indices_to_drop]\n",
        "            if not valid_indices:\n",
        "                break\n",
        "            idx = random.choice(valid_indices)\n",
        "            indices_to_drop.append(idx)\n",
        "        \n",
        "        augmented_tokens = [token for i, token in enumerate(augmented_tokens) if i not in indices_to_drop]\n",
        "    \n",
        "    elif augmentation_method == 'duplicate':\n",
        "        for _ in range(num_to_modify):\n",
        "            if not augmented_tokens:\n",
        "                break\n",
        "            idx = random.randint(0, len(augmented_tokens) - 1)\n",
        "            augmented_tokens.insert(idx, augmented_tokens[idx])\n",
        "    \n",
        "    elif augmentation_method == 'synonym':\n",
        "        variable_prefixes = ['_TokenType:i', '_TokenType:j', '_TokenType:k', '_TokenType:n', '_TokenType:m', '_TokenType:x', '_TokenType:y']\n",
        "        synonym_mapping = {\n",
        "            '_TokenType:i': ['_TokenType:idx', '_TokenType:index', '_TokenType:i'],\n",
        "            '_TokenType:j': ['_TokenType:jdx', '_TokenType:j'],\n",
        "            '_TokenType:k': ['_TokenType:kdx', '_TokenType:key', '_TokenType:k'],\n",
        "            '_TokenType:n': ['_TokenType:num', '_TokenType:size', '_TokenType:n'],\n",
        "            '_TokenType:m': ['_TokenType:max', '_TokenType:m'],\n",
        "            '_TokenType:x': ['_TokenType:xVal', '_TokenType:x'],\n",
        "            '_TokenType:y': ['_TokenType:yVal', '_TokenType:y']\n",
        "        }\n",
        "        \n",
        "        for _ in range(num_to_modify):\n",
        "            variable_indices = [i for i, token in enumerate(augmented_tokens) \n",
        "                               if any(token.startswith(prefix) for prefix in variable_prefixes)]\n",
        "            if not variable_indices:\n",
        "                break\n",
        "                \n",
        "            idx = random.choice(variable_indices)\n",
        "            token = augmented_tokens[idx]\n",
        "            \n",
        "            matching_prefix = next((prefix for prefix in variable_prefixes if token.startswith(prefix)), None)\n",
        "            if matching_prefix and matching_prefix in synonym_mapping:\n",
        "                augmented_tokens[idx] = random.choice(synonym_mapping[matching_prefix])\n",
        "    \n",
        "    return ' '.join(augmented_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e84814ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_augmented_pairs(token_pairs, labels, augmentation_factor=2):\n",
        "    \"\"\"\n",
        "    Generates augmented token pairs and corresponding labels.\n",
        "    \n",
        "    Args:\n",
        "        token_pairs (list): Original token pairs.\n",
        "        labels (list): Original labels.\n",
        "        augmentation_factor (int): Number of augmentations per original sample.\n",
        "        \n",
        "    Returns:\n",
        "        tuple: (augmented_pairs, augmented_labels)\n",
        "    \"\"\"\n",
        "    augmentation_methods = ['shuffle', 'drop', 'duplicate', 'synonym']\n",
        "    augmented_pairs = []\n",
        "    augmented_labels = []\n",
        "    \n",
        "    for pair, label in zip(token_pairs, labels):\n",
        "        augmented_pairs.append(pair)\n",
        "        augmented_labels.append(label)\n",
        "        \n",
        "        parts = pair.split(' ', 1)\n",
        "        if len(parts) < 2:\n",
        "            continue  \n",
        "        \n",
        "        token_seq1, token_seq2 = parts\n",
        "        \n",
        "        for _ in range(augmentation_factor):\n",
        "            method1 = random.choice(augmentation_methods)\n",
        "            method2 = random.choice(augmentation_methods)\n",
        "            \n",
        "            aug_seq1 = augment_token_sequence(token_seq1, method1, ratio=0.1)\n",
        "            aug_seq2 = augment_token_sequence(token_seq2, method2, ratio=0.1)\n",
        "            \n",
        "            augmented_pair = f\"{aug_seq1} {aug_seq2}\"\n",
        "            \n",
        "            augmented_pairs.append(augmented_pair)\n",
        "            augmented_labels.append(label)\n",
        "    \n",
        "    return augmented_pairs, augmented_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8f2ba6e1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original dataset size: 911\n",
            "Augmented dataset size: 2733\n",
            "\n",
            "Original class distribution:\n",
            "Label 0: 660 samples (72.45%)\n",
            "Label 1: 251 samples (27.55%)\n",
            "\n",
            "Augmented class distribution:\n",
            "Label 0: 1980 samples (72.45%)\n",
            "Label 1: 753 samples (27.55%)\n",
            "Augmented dataset size: 2733\n",
            "\n",
            "Original class distribution:\n",
            "Label 0: 660 samples (72.45%)\n",
            "Label 1: 251 samples (27.55%)\n",
            "\n",
            "Augmented class distribution:\n",
            "Label 0: 1980 samples (72.45%)\n",
            "Label 1: 753 samples (27.55%)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Original dataset size: {len(token_pairs)}\")\n",
        "augmented_token_pairs, augmented_labels = generate_augmented_pairs(token_pairs, labels, augmentation_factor=2)\n",
        "print(f\"Augmented dataset size: {len(augmented_token_pairs)}\")\n",
        "\n",
        "original_unique, original_counts = np.unique(labels, return_counts=True)\n",
        "augmented_unique, augmented_counts = np.unique(augmented_labels, return_counts=True)\n",
        "\n",
        "print(f\"\\nOriginal class distribution:\")\n",
        "for label, count in zip(original_unique, original_counts):\n",
        "    print(f\"Label {label}: {count} samples ({count/len(labels)*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\nAugmented class distribution:\")\n",
        "for label, count in zip(augmented_unique, augmented_counts):\n",
        "    print(f\"Label {label}: {count} samples ({count/len(augmented_labels)*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a720ed8",
      "metadata": {},
      "source": [
        "## Similitud de Cosenos\n",
        "\n",
        "La similitud de cosenos es una medida de similitud entre dos vectores no nulos que mide el coseno del ángulo entre ellos. En el contexto de detección de plagio, se utiliza para comparar la similitud entre dos representaciones vectoriales de documentos (en este caso, códigos fuente).\n",
        "\n",
        "A continuación se implementa una función para calcular la similitud de cosenos entre dos vectores, inspirada en la implementación del archivo act43.py:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7c22034a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between test vectors: 0.6667\n"
          ]
        }
      ],
      "source": [
        "def calculate_cosine_similarity(vec1, vec2):\n",
        "    \"\"\"\n",
        "    Calculates cosine similarity between two vectors.\n",
        "    \n",
        "    Args:\n",
        "        vec1, vec2 (numpy.array): The vectors to compare\n",
        "        \n",
        "    Returns:\n",
        "        float: Cosine similarity score between 0 and 1\n",
        "    \"\"\"\n",
        "    norm_vec1 = np.linalg.norm(vec1)\n",
        "    norm_vec2 = np.linalg.norm(vec2)\n",
        "    \n",
        "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    similarity = np.dot(vec1, vec2) / (norm_vec1 * norm_vec2)\n",
        "    return similarity\n",
        "\n",
        "vec1 = np.array([1, 0, 1, 1])\n",
        "vec2 = np.array([1, 1, 0, 1])\n",
        "print(f\"Cosine similarity between test vectors: {calculate_cosine_similarity(vec1, vec2):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adda2e53",
      "metadata": {},
      "source": [
        "## Implementación manual de TF-IDF\n",
        "\n",
        "A continuación, implementamos una función para calcular TF-IDF de manera manual, similar a la implementación en act43.py. Esto nos permitirá comparar los resultados con la implementación automatizada de scikit-learn que usamos en nuestro modelo principal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b803d641",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_manual_tfidf(code1, code2):\n",
        "    \"\"\"\n",
        "    Computes TF-IDF vectors for two code samples manually, similar to act43.py approach.\n",
        "    \n",
        "    Args:\n",
        "        code1, code2 (str): Java source code strings\n",
        "        \n",
        "    Returns:\n",
        "        dict: Dictionary with TF-IDF vectors for both code samples\n",
        "    \"\"\"\n",
        "    tokens1 = extract_tokens(code1).split()\n",
        "    tokens2 = extract_tokens(code2).split()\n",
        "    \n",
        "    unique_tokens = list(set(tokens1 + tokens2))\n",
        "    \n",
        "    counts1 = Counter(tokens1)\n",
        "    counts2 = Counter(tokens2)\n",
        "    \n",
        "    tfidf_vec1 = np.zeros(len(unique_tokens))\n",
        "    tfidf_vec2 = np.zeros(len(unique_tokens))\n",
        "    \n",
        "    for i, token in enumerate(unique_tokens):\n",
        "        tf1 = counts1[token] / max(len(tokens1), 1)\n",
        "        tf2 = counts2[token] / max(len(tokens2), 1)\n",
        "        \n",
        "        doc_count = (counts1[token] > 0) + (counts2[token] > 0)\n",
        "        \n",
        "        idf = np.log(2 / doc_count) + 1\n",
        "        \n",
        "        tfidf_vec1[i] = tf1 * idf\n",
        "        tfidf_vec2[i] = tf2 * idf\n",
        "    \n",
        "    result = {\n",
        "        'q1_vec': tfidf_vec1,\n",
        "        'q2_vec': tfidf_vec2,\n",
        "        'tokens': unique_tokens\n",
        "    }\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "17ba6ac1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_code_similarity_tfidf(id1, id2, code1, code2):\n",
        "    \"\"\"\n",
        "    Compares two code samples using manual TF-IDF implementation and cosine similarity.\n",
        "    \n",
        "    Args:\n",
        "        id1, id2 (str): Identifiers for the code samples\n",
        "        code1, code2 (str): Java source code strings\n",
        "        \n",
        "    Returns:\n",
        "        float: Cosine similarity score between the TF-IDF vectors\n",
        "    \"\"\"\n",
        "    tfidf_dict = compute_manual_tfidf(code1, code2)\n",
        "    \n",
        "    similarity = calculate_cosine_similarity(tfidf_dict['q1_vec'], tfidf_dict['q2_vec'])\n",
        "    \n",
        "    print(f\"Similarity between {id1} and {id2}: {similarity:.4f}\")\n",
        "    \n",
        "    if len(tfidf_dict['tokens']) > 0 and similarity > 0.5:\n",
        "        contribution = tfidf_dict['q1_vec'] * tfidf_dict['q2_vec']\n",
        "        top_indices = np.argsort(contribution)[-10:] if len(contribution) >= 10 else np.argsort(contribution)\n",
        "        top_tokens = [(tfidf_dict['tokens'][i], contribution[i]) for i in top_indices]\n",
        "        print(\"Top contributing tokens:\")\n",
        "        for token, score in reversed(top_tokens):\n",
        "            if score > 0:\n",
        "                print(f\"{token}: {score:.4f}\")\n",
        "    \n",
        "    return similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c7c17248",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing with 5 sample pairs...\n",
            "\n",
            "\n",
            "Pair 1:\n",
            "Similarity between 0017d438 and 9852706b: 0.6414\n",
            "Top contributing tokens:\n",
            "_TokenType:=: 0.0095\n",
            "_TokenType:int: 0.0059\n",
            "_TokenType:i: 0.0017\n",
            "_TokenType:<: 0.0016\n",
            "_TokenType:+: 0.0015\n",
            "_TokenType:>: 0.0011\n",
            "_TokenType:nextInt: 0.0009\n",
            "_TokenType:import: 0.0009\n",
            "_TokenType:new: 0.0007\n",
            "_TokenType:static: 0.0006\n",
            "Actual verdict: Plagiarism\n",
            "\n",
            "Pair 2:\n",
            "Similarity between 0017d438 and ac180326: 0.6045\n",
            "Top contributing tokens:\n",
            "_TokenType:=: 0.0073\n",
            "_TokenType:int: 0.0035\n",
            "_TokenType:+: 0.0026\n",
            "_TokenType:i: 0.0021\n",
            "_TokenType:<: 0.0015\n",
            "_TokenType:]: 0.0014\n",
            "_TokenType:[: 0.0014\n",
            "_TokenType:import: 0.0013\n",
            "_TokenType:new: 0.0005\n",
            "_TokenType:Pair: 0.0004\n",
            "Actual verdict: No plagiarism\n",
            "\n",
            "Pair 3:\n",
            "Similarity between 0048a372 and 0adb1ee5: 0.7518\n",
            "Top contributing tokens:\n",
            "_TokenType:i: 0.0089\n",
            "_TokenType:=: 0.0083\n",
            "_TokenType:]: 0.0043\n",
            "_TokenType:[: 0.0043\n",
            "_TokenType:+: 0.0022\n",
            "_TokenType:int: 0.0017\n",
            "_TokenType:long: 0.0009\n",
            "_TokenType:n: 0.0007\n",
            "_TokenType:<: 0.0006\n",
            "_TokenType:k: 0.0005\n",
            "Actual verdict: No plagiarism\n",
            "\n",
            "Pair 4:\n",
            "Similarity between 00af3420 and 5449d33c: 0.7749\n",
            "Top contributing tokens:\n",
            "_TokenType:=: 0.0155\n",
            "_TokenType:+: 0.0051\n",
            "_TokenType:int: 0.0033\n",
            "_TokenType:i: 0.0031\n",
            "_TokenType:]: 0.0015\n",
            "_TokenType:[: 0.0015\n",
            "_TokenType:<: 0.0007\n",
            "_TokenType:n: 0.0006\n",
            "_TokenType:for: 0.0005\n",
            "_TokenType:new: 0.0005\n",
            "Actual verdict: No plagiarism\n",
            "\n",
            "Pair 5:\n",
            "Similarity between 00af3420 and 86102d81: 0.7953\n",
            "Top contributing tokens:\n",
            "_TokenType:=: 0.0146\n",
            "_TokenType:+: 0.0062\n",
            "_TokenType:int: 0.0037\n",
            "_TokenType:i: 0.0022\n",
            "_TokenType:]: 0.0017\n",
            "_TokenType:[: 0.0017\n",
            "_TokenType:n: 0.0007\n",
            "_TokenType:<: 0.0007\n",
            "_TokenType:-: 0.0006\n",
            "_TokenType:for: 0.0006\n",
            "Actual verdict: No plagiarism\n"
          ]
        }
      ],
      "source": [
        "sample_size = min(5, len(java_files_data) // 2)\n",
        "print(f\"Testing with {sample_size} sample pairs...\\n\")\n",
        "\n",
        "for i in range(0, sample_size*2, 2):\n",
        "    try:\n",
        "        id1, code1 = java_files_data[i]\n",
        "        id2, code2 = java_files_data[i+1]\n",
        "        \n",
        "        print(f\"\\nPair {i//2 + 1}:\")\n",
        "        similarity = compare_code_similarity_tfidf(id1, id2, code1, code2)\n",
        "        \n",
        "        if (id1, id2) in labels_dict:\n",
        "            verdict = labels_dict[(id1, id2)]\n",
        "            print(f\"Actual verdict: {'Plagiarism' if verdict == 1 else 'No plagiarism'}\")\n",
        "        elif (id2, id1) in labels_dict:\n",
        "            verdict = labels_dict[(id2, id1)]\n",
        "            print(f\"Actual verdict: {'Plagiarism' if verdict == 1 else 'No plagiarism'}\")\n",
        "        else:\n",
        "            print(\"No verdict available for this pair\")\n",
        "    except IndexError:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25fedde8",
      "metadata": {},
      "source": [
        "## Implementación de TF-IDF con scikit-learn\n",
        "\n",
        "A continuación implementaremos la similitud de cosenos utilizando TF-IDF con scikit-learn, para comparar con nuestra implementación manual anterior basada en act43.py y con el modelo de machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e3e8ee6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_sklearn_tfidf_similarity(code1, code2):\n",
        "    \"\"\"\n",
        "    Calculate TF-IDF based similarity between two code samples using scikit-learn.\n",
        "    \n",
        "    Args:\n",
        "        code1, code2 (str): Source code strings\n",
        "        \n",
        "    Returns:\n",
        "        float: Similarity score\n",
        "        dict: Dictionary with TF-IDF vectors and feature names\n",
        "    \"\"\"\n",
        "    # Preprocess code\n",
        "    processed_code1 = extract_tokens(code1)\n",
        "    processed_code2 = extract_tokens(code2)\n",
        "    \n",
        "    # Create corpus\n",
        "    corpus = [processed_code1, processed_code2]\n",
        "    \n",
        "    # Initialize and fit TF-IDF vectorizer\n",
        "    vectorizer = TfidfVectorizer(lowercase=True)\n",
        "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "    \n",
        "    # Get feature names\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    \n",
        "    # Convert sparse matrix to dense arrays\n",
        "    vec1 = tfidf_matrix[0].toarray().flatten()\n",
        "    vec2 = tfidf_matrix[1].toarray().flatten()\n",
        "    \n",
        "    # Calculate similarity (1 - cosine distance)\n",
        "    if np.all(vec1 == 0) or np.all(vec2 == 0):\n",
        "        similarity = 0.0\n",
        "    else:\n",
        "        similarity = 1 - cosine(vec1, vec2)\n",
        "    \n",
        "    # Prepare return dictionary\n",
        "    result = {\n",
        "        'q1_vec': vec1,\n",
        "        'q2_vec': vec2,\n",
        "        'tokens': feature_names,\n",
        "        'similarity': similarity\n",
        "    }\n",
        "    \n",
        "    return similarity, result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d0750b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_top_contributing_tokens(tfidf_result, top_n=10):\n",
        "    \"\"\"\n",
        "    Find the tokens that contribute most to the similarity score\n",
        "    \n",
        "    Args:\n",
        "        tfidf_result (dict): Dictionary with TF-IDF vectors and feature names\n",
        "        top_n (int): Number of top tokens to return\n",
        "        \n",
        "    Returns:\n",
        "        list: List of (token, contribution_score) tuples\n",
        "    \"\"\"\n",
        "    tokens = tfidf_result['tokens']\n",
        "    vec1 = tfidf_result['q1_vec']\n",
        "    vec2 = tfidf_result['q2_vec']\n",
        "    \n",
        "    # Calculate contribution as product of corresponding values in both vectors\n",
        "    contribution = vec1 * vec2\n",
        "    \n",
        "    # Get indices of top contributors\n",
        "    top_indices = contribution.argsort()[-top_n:][::-1]\n",
        "    \n",
        "    # Return token and contribution pairs\n",
        "    top_tokens = [(tokens[i], contribution[i]) for i in top_indices if contribution[i] > 0]\n",
        "    \n",
        "    return top_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82dadafe",
      "metadata": {},
      "source": [
        "## Comparación entre implementación manual y scikit-learn\n",
        "\n",
        "Ahora compararemos la implementación manual de TF-IDF (basada en act43.py) con la implementación utilizando scikit-learn para los mismos pares de código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a40b1e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_implementations(id1, id2, code1, code2):\n",
        "    \"\"\"\n",
        "    Compare manual and scikit-learn TF-IDF implementations for code similarity.\n",
        "    \n",
        "    Args:\n",
        "        id1, id2 (str): Identifiers for the code samples\n",
        "        code1, code2 (str): Java source code strings\n",
        "    \"\"\"\n",
        "    print(f\"Comparing implementations for {id1} and {id2}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Manual implementation (act43.py style)\n",
        "    manual_tfidf_dict = compute_manual_tfidf(code1, code2)\n",
        "    manual_similarity = calculate_cosine_similarity(manual_tfidf_dict['q1_vec'], manual_tfidf_dict['q2_vec'])\n",
        "    print(f\"Manual TF-IDF similarity: {manual_similarity:.4f}\")\n",
        "    \n",
        "    # scikit-learn implementation\n",
        "    sklearn_similarity, sklearn_result = get_sklearn_tfidf_similarity(code1, code2)\n",
        "    print(f\"scikit-learn TF-IDF similarity: {sklearn_similarity:.4f}\")\n",
        "    \n",
        "    # Get top contributing tokens from scikit-learn implementation\n",
        "    top_tokens = get_top_contributing_tokens(sklearn_result)\n",
        "    \n",
        "    # Check if we have labels for this pair\n",
        "    if (id1, id2) in labels_dict:\n",
        "        verdict = labels_dict[(id1, id2)]\n",
        "        print(f\"Actual verdict: {'Plagiarism' if verdict == 1 else 'No plagiarism'}\")\n",
        "    elif (id2, id1) in labels_dict:\n",
        "        verdict = labels_dict[(id2, id1)]\n",
        "        print(f\"Actual verdict: {'Plagiarism' if verdict == 1 else 'No plagiarism'}\")\n",
        "    else:\n",
        "        print(\"No verdict available for this pair\")\n",
        "        verdict = None\n",
        "    \n",
        "    # Print top contributing tokens\n",
        "    if len(top_tokens) > 0:\n",
        "        print(\"\\nTop tokens contributing to similarity (scikit-learn):\")\n",
        "        for token, score in top_tokens:\n",
        "            print(f\"  {token}: {score:.6f}\")\n",
        "    \n",
        "    return {\n",
        "        'manual_similarity': manual_similarity,\n",
        "        'sklearn_similarity': sklearn_similarity,\n",
        "        'verdict': verdict\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9973ba73",
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_size = min(5, len(java_files_data) // 2)\n",
        "print(f\"Comparing implementations on {sample_size} sample pairs...\\n\")\n",
        "\n",
        "comparison_results = []\n",
        "\n",
        "for i in range(0, sample_size*2, 2):\n",
        "    try:\n",
        "        id1, code1 = java_files_data[i]\n",
        "        id2, code2 = java_files_data[i+1]\n",
        "        \n",
        "        print(f\"\\nPair {i//2 + 1}:\")\n",
        "        result = compare_implementations(id1, id2, code1, code2)\n",
        "        comparison_results.append(result)\n",
        "        \n",
        "    except IndexError:\n",
        "        break\n",
        "        \n",
        "# Convert results to DataFrame for analysis\n",
        "comparison_df = pd.DataFrame(comparison_results)\n",
        "print(\"\\nSummary of comparison results:\")\n",
        "print(comparison_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f13c590",
      "metadata": {},
      "source": [
        "## Comparación de scikit-learn TF-IDF con el modelo de ML\n",
        "\n",
        "Ahora compararemos los resultados de la similitud de cosenos TF-IDF utilizando scikit-learn con los resultados de nuestro modelo de machine learning para ver qué enfoque proporciona mejores resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ab51f51",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_tfidf_with_model(model, test_size=10):\n",
        "    \"\"\"\n",
        "    Compare TF-IDF similarity with ML model predictions.\n",
        "    \n",
        "    Args:\n",
        "        model: Trained ML model\n",
        "        test_size (int): Number of pairs to test\n",
        "    \"\"\"\n",
        "    # Use a subset of data for testing\n",
        "    test_indices = np.random.choice(len(java_files_data)//2, test_size, replace=False)\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for idx in test_indices:\n",
        "        try:\n",
        "            id1, code1 = java_files_data[idx*2]\n",
        "            id2, code2 = java_files_data[idx*2 + 1]\n",
        "            \n",
        "            # Calculate TF-IDF similarity\n",
        "            tfidf_similarity, _ = get_sklearn_tfidf_similarity(code1, code2)\n",
        "            \n",
        "            # Process for model input\n",
        "            t1 = extract_tokens(code1)\n",
        "            t2 = extract_tokens(code2)\n",
        "            tokens_pair = f\"{t1} {t2}\"\n",
        "            \n",
        "            # Transform using the same vectorizer\n",
        "            pair_vector = vectorizer.transform([tokens_pair]).toarray()\n",
        "            \n",
        "            # Get model prediction\n",
        "            model_prediction = model.predict(pair_vector)[0]\n",
        "            model_prob = model.predict_proba(pair_vector)[0][1] if hasattr(model, 'predict_proba') else None\n",
        "            \n",
        "            # Get actual label if available\n",
        "            if (id1, id2) in labels_dict:\n",
        "                actual = labels_dict[(id1, id2)]\n",
        "            elif (id2, id1) in labels_dict:\n",
        "                actual = labels_dict[(id2, id1)]\n",
        "            else:\n",
        "                actual = None\n",
        "                \n",
        "            results.append({\n",
        "                'pair_id': f\"{id1}_{id2}\",\n",
        "                'tfidf_similarity': tfidf_similarity,\n",
        "                'model_prediction': model_prediction,\n",
        "                'model_probability': model_prob,\n",
        "                'actual': actual\n",
        "            })\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing pair at index {idx}: {e}\")\n",
        "    \n",
        "    return pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83174a6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Choose the best model for comparison (Random Forest in this example)\n",
        "best_model = rf_model\n",
        "\n",
        "# Compare with TF-IDF\n",
        "comparison_results = compare_tfidf_with_model(best_model, test_size=15)\n",
        "print(comparison_results)\n",
        "\n",
        "# Calculate accuracy of TF-IDF with threshold 0.7\n",
        "valid_results = comparison_results.dropna(subset=['actual'])\n",
        "if not valid_results.empty:\n",
        "    tfidf_predictions = (valid_results['tfidf_similarity'] > 0.7).astype(int)\n",
        "    tfidf_accuracy = (tfidf_predictions == valid_results['actual']).mean()\n",
        "    model_accuracy = (valid_results['model_prediction'] == valid_results['actual']).mean()\n",
        "    \n",
        "    print(f\"\\nTF-IDF accuracy with threshold 0.7: {tfidf_accuracy:.4f}\")\n",
        "    print(f\"Model accuracy: {model_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a72680f2",
      "metadata": {},
      "source": [
        "## Visualización de resultados\n",
        "\n",
        "Visualizamos la comparación entre la similitud TF-IDF y las predicciones del modelo para entender mejor la relación entre ambos enfoques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afc545c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Filter for rows with actual labels\n",
        "plot_df = comparison_results.dropna(subset=['actual'])\n",
        "\n",
        "if not plot_df.empty:\n",
        "    # Plot points colored by actual label\n",
        "    scatter = plt.scatter(plot_df['tfidf_similarity'], \n",
        "              plot_df['model_probability'] if 'model_probability' in plot_df.columns else plot_df['model_prediction'],\n",
        "              c=plot_df['actual'], \n",
        "              cmap='coolwarm', \n",
        "              s=100,\n",
        "              alpha=0.7)\n",
        "    \n",
        "    plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
        "    plt.axvline(x=0.7, color='gray', linestyle='--', alpha=0.5)\n",
        "    \n",
        "    plt.xlabel('TF-IDF Cosine Similarity')\n",
        "    plt.ylabel('Model Probability of Plagiarism' if 'model_probability' in plot_df.columns else 'Model Prediction')\n",
        "    plt.title('Comparison of TF-IDF Similarity vs Model Predictions')\n",
        "    \n",
        "    # Add a legend\n",
        "    legend1 = plt.legend(*scatter.legend_elements(),\n",
        "                        title=\"Actual Label\")\n",
        "    plt.gca().add_artist(legend1)\n",
        "    \n",
        "    # Annotate the quadrants\n",
        "    plt.text(0.35, 0.75, 'Model: Yes\\nTF-IDF: No', ha='center', va='center', alpha=0.7)\n",
        "    plt.text(0.85, 0.75, 'Both: Yes\\n(True Positive)', ha='center', va='center', alpha=0.7)\n",
        "    plt.text(0.35, 0.25, 'Both: No\\n(True Negative)', ha='center', va='center', alpha=0.7)\n",
        "    plt.text(0.85, 0.25, 'Model: No\\nTF-IDF: Yes', ha='center', va='center', alpha=0.7)\n",
        "    \n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No labeled data available for visualization\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6d1b448",
      "metadata": {},
      "outputs": [],
      "source": [
        "# voting_model_final_refined.fit(X_train_resampled, y_train_resampled)\n",
        "# final_result = evaluate_model('Ensemble Final', voting_model_final_refined, X_test, y_test)\n",
        "\n",
        "# print(f\"Accuracy: {final_result['accuracy']:.4f}\")\n",
        "# print(f\"Precision: {final_result['precision']:.4f}\")\n",
        "# print(f\"Recall: {final_result['recall']:.4f}\")\n",
        "# print(f\"F1-Score: {final_result['f1']:.4f}\")\n",
        "# print(f\"MCC: {final_result['mcc']:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
